# Ollama-MCP-Server

**Author/Maintainer:** [Mupoese](https://github.com/mupoese)  
**Version:** v1.0.1  
**License:** GNU General Public License v2.0  
**AI Compliance:** LAW-001 (Comprehensive AI Learning Cycle)

## ðŸš€ AI-Enhanced MCP Server

This Ollama MCP Server has been enhanced with comprehensive AI law enforcement and learning cycle capabilities, implementing LAW-001 requirements for:

- **6-Step Learning Cycle**: Automatic execution on cause detection
- **Snapshot Generation**: JSON schema-based memory system
- **Pattern Detection**: Systematic deviation analysis
- **Governance Framework**: Automated approval system for AI core updates
- **Law Enforcement**: Real-time compliance validation

### ðŸ¤– AI Core Features

- **Automatic Learning Cycles**: Every tool execution triggers a complete 6-step learning cycle
- **Memory Persistence**: Snapshots automatically saved and loaded on startup
- **Pattern Recognition**: Detects systematic deviations and triggers escalation
- **Governance Control**: All core AI logic changes require explicit approval
- **Law Compliance**: Full adherence to LAW-001 requirements

## Docker Usage Options

### Option 1: Use Pre-built Image (Recommended)

```bash
# Pull and run from Docker Hub
docker run -i --rm --network host \
  -e OLLAMA_API=http://localhost:11434 \
  docker.io/mup1987/ollama-mcp-server:latest
```

### Option 2: Build Your Own Image

```bash
# Clone, build, and run locally
git clone https://github.com/mupoese/Ollama-MCP-Server.git
cd Ollama-MCP-Server
docker build -t my-ollama-mcp-server .
docker run -i --rm --network host \
  -e OLLAMA_API=http://localhost:11434 \
  my-ollama-mcp-server
```

### Option 3: Docker Compose (Production)

Create a `docker-compose.yml`:

```yaml
version: '3.8'
services:
  ollama-mcp-server:
    image: docker.io/mup1987/ollama-mcp-server:latest
    environment:
      - OLLAMA_API=http://host.docker.internal:11434
    stdin_open: true
    restart: unless-stopped
    depends_on:
      - ollama
  
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped

volumes:
  ollama_data:
```

Run with: `docker-compose up -d`

---

## Overview

**Ollama-MCP-Server** is a custom, extensible MCP (Model Context Protocol) server that bridges local or remote Ollama LLM models with any MCP-compatible application, such as Claude Desktop.  
This project offers maximum flexibility, privacy, open source usage, and professional integration.

---

## Changelog

### v1.0.1

- **Enhanced Documentation**: Added comprehensive MCP protocol communication documentation
- **JSON-RPC Functions**: Detailed documentation of all available JSON-RPC functions and their usage
- **Port Communication**: Documented port usage (11434 for Ollama, stdin/stdout for MCP)
- **Architecture Documentation**: Added communication flow diagrams and architecture details

### v1.0.0

- First stable release
- Full MCP protocol support with JSON-RPC over stdin/stdout
- **ES Modules**: Converted from CommonJS to ES modules for MCP SDK compatibility
- Docker support for Windows, Mac, and Linux
- Integration instructions for Claude Desktop
- Complete error handling and logging
- **SILENCE_STARTUP support**: Prevents stdout pollution that breaks MCP protocol
- Proper MCP SDK implementation with `@modelcontextprotocol/sdk`

---

## Key Features

- **Proper MCP Protocol**: Implements JSON-RPC over stdin/stdout (not HTTP REST)
- **ES Modules**: Uses modern ES module syntax for MCP SDK compatibility
- **MCP Tools**: List models, chat, generate text, pull models
- **Docker Support**: Ready-to-deploy container
- **Environment Variables**: Configure via Docker `-e` or local `.env`
- **Claude Desktop Integration**: Works seamlessly with Claude Desktop
- **SILENCE_STARTUP**: Prevents console output that interferes with MCP protocol
- **Extensible**: Add custom authentication, logging, dashboards, etc.
- **Fast Deployment**: Quick to build and deploy

---

## System Requirements

- Node.js v18+ (for local testing)
- npm (for local testing)
- Ollama installed and running locally, or remote Ollama API
- Docker (recommended for production/desktop integration)
- Git

---

## Important: MCP vs HTTP

This server implements the **Model Context Protocol (MCP)**, which uses JSON-RPC over stdin/stdout, **not HTTP REST API**. 

- âœ… **Correct**: MCP server for Claude Desktop integration
- âŒ **Incorrect**: HTTP REST API server

---

## ðŸ”Œ MCP Protocol Communication Architecture

### Communication Flow Overview

The Ollama MCP Server acts as a bridge between MCP clients (like Claude Desktop) and Ollama API, implementing a dual-protocol architecture:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    JSON-RPC     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    HTTP REST    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MCP Client    â”‚â—„â”€stdin/stdoutâ”€â”€â–ºâ”‚  Ollama-MCP     â”‚â—„â”€â”€port 11434â”€â”€â”€â–ºâ”‚   Ollama API    â”‚
â”‚ (Claude Desktop)â”‚                 â”‚     Server      â”‚                 â”‚   (LLM Models)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Port Usage and Communication Protocols

| Component | Protocol | Port/Interface | Purpose |
|-----------|----------|---------------|----------|
| **MCP Client â†” MCP Server** | JSON-RPC | stdin/stdout | Model Context Protocol communication |
| **MCP Server â†” Ollama** | HTTP REST | 11434 | Ollama API calls for model operations |

### JSON-RPC Functions Documentation

The server implements the Model Context Protocol (MCP) specification with the following JSON-RPC methods:

#### Core MCP Methods

**1. `listTools`**
- **Purpose**: Returns all available MCP tools
- **Request**: No parameters required
- **Response**: Array of tool definitions with schemas
- **Example**:
  ```json
  {
    "jsonrpc": "2.0",
    "id": 1,
    "method": "tools/list",
    "params": {}
  }
  ```

**2. `callTool`**
- **Purpose**: Executes a specific tool with provided arguments
- **Request**: Tool name and arguments object
- **Response**: Tool execution result
- **Example**:
  ```json
  {
    "jsonrpc": "2.0",
    "id": 2,
    "method": "tools/call",
    "params": {
      "name": "ollama_chat",
      "arguments": {
        "model": "llama2",
        "messages": [{"role": "user", "content": "Hello!"}]
      }
    }
  }
  ```

### Available MCP Tools

#### Ollama Core Tools

| Tool Name | Purpose | Ollama API Endpoint |
|-----------|---------|-------------------|
| `ollama_list_models` | List available models | `GET /api/tags` |
| `ollama_chat` | Chat with model | `POST /api/chat` |
| `ollama_generate` | Generate text | `POST /api/generate` |
| `ollama_pull_model` | Download model | `POST /api/pull` |

#### Development Tools

| Tool Name | Purpose | Description |
|-----------|---------|-------------|
| `code_feedback` | Code analysis | AI-powered code review and feedback |
| `terminal_execute` | Command execution | Execute shell commands with safety checks |
| `file_read` | File operations | Read file contents |
| `file_write` | File operations | Write file contents |
| `file_list` | File operations | List directory contents |

#### Testing & Quality Tools

| Tool Name | Purpose | Description |
|-----------|---------|-------------|
| `test_run` | Test execution | Run project tests |
| `test_discover` | Test discovery | Find test files |
| `lint_check` | Code linting | Run code quality checks |
| `audit_security` | Security audit | Security vulnerability scanning |

#### Server Management Tools

| Tool Name | Purpose | Description |
|-----------|---------|-------------|
| `server_status` | Status check | Get server health status |
| `validate_config` | Config validation | Validate server configuration |

### Communication Protocol Details

#### MCP Protocol (Client â†” Server)

**Transport**: stdio (stdin/stdout)  
**Protocol**: JSON-RPC 2.0  
**Message Format**:
```json
{
  "jsonrpc": "2.0",
  "id": "unique-request-id",
  "method": "method-name",
  "params": { /* method parameters */ }
}
```

**Key Features**:
- Bidirectional communication over stdio
- No HTTP headers or REST endpoints
- All logging must go to stderr (not stdout) to avoid protocol interference
- `SILENCE_STARTUP=true` prevents stdout pollution

#### HTTP Protocol (Server â†” Ollama)

**Transport**: HTTP/HTTPS  
**Default Endpoint**: `http://host.docker.internal:11434`  
**Protocol**: REST API  
**Authentication**: None (local API)  

**Request Configuration**:
- Content-Type: `application/json`
- Timeout: 30 seconds (configurable)
- Retry Logic: 3 attempts with exponential backoff
- Error Handling: Automatic retry for 5xx errors, timeouts, and connection issues

### Environment Configuration

| Variable | Default | Description |
|----------|---------|-------------|
| `OLLAMA_API` | `http://host.docker.internal:11434` | Ollama API endpoint |
| `SILENCE_STARTUP` | `false` | Suppress startup logs for MCP compatibility |
| `REQUEST_TIMEOUT` | `30000` | HTTP request timeout (ms) |
| `MAX_RETRIES` | `3` | HTTP request retry attempts |

### Error Handling

**MCP Protocol Errors**:
- Invalid tool names return `MethodNotFound` error
- Validation failures return `InvalidParams` error
- Internal errors return `InternalError` with details

**HTTP Protocol Errors**:
- Connection failures trigger automatic retry
- 4xx errors (client errors) are not retried
- 5xx errors (server errors) trigger retry with backoff

---

## Installation & Usage

### 1. Clone the Repository

```bash
git clone https://github.com/mupoese/Ollama-MCP-Server.git
cd Ollama-MCP-Server
```

### 2. Install Dependencies

```bash
npm install
```

### 3. Build Docker Image

```bash
docker build -t ollama-mcp-server .
```

### 4. Test the Server

```bash
# Test with Docker (Linux/Mac)
docker run -i --rm \
  -e OLLAMA_API=http://host.docker.internal:11434 \
  -e SILENCE_STARTUP=true \
  ollama-mcp-server

# Test with Docker (Windows PowerShell - single line)
docker run -i --rm -e OLLAMA_API=http://host.docker.internal:11434 -e SILENCE_STARTUP=true ollama-mcp-server
```

### 5. Publish to Docker Hub (Optional)

```bash
# Tag your image
docker tag ollama-mcp-server docker.io/mup1987/ollama-mcp-server:latest

# Push to Docker Hub
docker push docker.io/mup1987/ollama-mcp-server:latest
```

---

## Claude Desktop Integration

### Configuration File Location

- **Windows**: `%APPDATA%\Claude\claude_desktop_config.json`
- **Mac**: `~/Library/Application Support/Claude/claude_desktop_config.json`

### MCP Configuration

Add this to your Claude Desktop MCP configuration:

**Complete Configuration (with GitHub MCP Server):**
```json
{
  "mcpServers": {
    "github": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "-e",
        "GITHUB_PERSONAL_ACCESS_TOKEN",
        "ghcr.io/github/github-mcp-server"
      ],
      "env": {
        "GITHUB_PERSONAL_ACCESS_TOKEN": "your_github_token_here"
      }
    },
    "ollama-mcp": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "-e",
        "OLLAMA_API=http://host.docker.internal:11434",
        "-e",
        "SILENCE_STARTUP=true",
        "docker.io/mup1987/ollama-mcp-server:latest"
      ],
      "env": {
        "OLLAMA_API": "http://host.docker.internal:11434",
        "SILENCE_STARTUP": "true"
      }
    }
  }
}
```

**Ollama-Only Configuration:**
```json
{
  "mcpServers": {
    "ollama-mcp": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "-e",
        "OLLAMA_API=http://host.docker.internal:11434",
        "-e",
        "SILENCE_STARTUP=true",
        "docker.io/mup1987/ollama-mcp-server:latest"
      ],
      "env": {
        "OLLAMA_API": "http://host.docker.internal:11434",
        "SILENCE_STARTUP": "true"
      }
    }
  }
}
```

**Using Local Docker Build:**
```json
{
  "mcpServers": {
    "ollama-mcp": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "-e",
        "OLLAMA_API=http://host.docker.internal:11434",
        "-e",
        "SILENCE_STARTUP=true",
        "ollama-mcp-server"
      ],
      "env": {
        "OLLAMA_API": "http://host.docker.internal:11434",
        "SILENCE_STARTUP": "true"
      }
    }
  }
}
```

### Platform-Specific OLLAMA_API Settings

| Platform        | OLLAMA_API Setting                       |
| --------------- | ---------------------------------------- |
| **Windows/Mac** | `http://host.docker.internal:11434`     |
| **Linux**       | `http://localhost:11434` or `http://172.17.0.1:11434` |

> **Note**: Your configuration uses `host.docker.internal` which works well for Windows/Mac. Linux users may need to adjust to their Docker bridge IP.

---

## Available MCP Tools

Once connected to Claude Desktop, these tools become available:

### Core Ollama Tools
| Tool Name           | Description                              |
| ------------------- | ---------------------------------------- |
| `ollama_list_models`| List all available Ollama models        |
| `ollama_chat`       | Chat with an Ollama model               |
| `ollama_generate`   | Generate text with an Ollama model      |
| `ollama_pull_model` | Pull/download a model from registry     |

### ðŸ› ï¸ Development & Testing Tools
| Tool Name           | Description                              |
| ------------------- | ---------------------------------------- |
| `terminal_execute`  | Execute shell commands in controlled environment |
| `test_run`         | Run Jest tests with configurable options |
| `test_discover`    | Discover and list available test files   |

### ðŸ“ File Management Tools
| Tool Name           | Description                              |
| ------------------- | ---------------------------------------- |
| `file_read`        | Read file contents with encoding support |
| `file_write`       | Write content to files with backup options |
| `file_list`        | List files and directories with filtering |

### ðŸ” Code Quality Tools
| Tool Name           | Description                              |
| ------------------- | ---------------------------------------- |
| `lint_check`       | Run ESLint with auto-fix capabilities   |
| `audit_security`   | Run npm security audit on dependencies  |

### âš™ï¸ Server Management Tools
| Tool Name           | Description                              |
| ------------------- | ---------------------------------------- |
| `server_status`    | Get MCP server status and diagnostics   |
| `validate_config`  | Validate MCP server configuration       |

### Tool Usage Examples

#### Terminal Operations
```javascript
// Execute a safe command
terminal_execute({
  command: "npm test",
  workingDirectory: "/path/to/project",
  timeout: 60
})

// List project files
file_list({
  path: ".",
  pattern: "*.js",
  recursive: true,
  details: true
})
```

#### Testing & Quality
```javascript
// Run specific tests
test_run({
  testPath: "tests/config.test.js",
  coverage: true,
  verbose: true
})

// Check code quality
lint_check({
  path: "src/",
  fix: true,
  format: "stylish"
})

// Security audit
audit_security({
  level: "high",
  fix: false
})
```

#### File Operations
```javascript
// Read configuration file
file_read({
  path: "package.json",
  encoding: "utf8"
})

// Write with backup
file_write({
  path: "config.json",
  content: JSON.stringify(config, null, 2),
  backup: true,
  createDirectories: true
})
```

#### Server Management
```javascript
// Check server status
server_status({
  detailed: true
})

// Validate configuration
validate_config({
  showDetails: true
})
```

### Security Features

- **Path Security**: File operations prevent access to system directories (`/etc/`, `/sys/`)
- **Command Filtering**: Terminal execution blocks dangerous commands (`rm -rf`, `sudo`, etc.)
- **File Size Limits**: File reads limited to prevent memory exhaustion
- **Timeout Protection**: All operations have configurable timeouts

---

## Local Development (No Docker)

For local development without Docker:

```bash
# Install dependencies
npm install

# Start the MCP server
node server.js
```

**Claude Desktop config for local usage:**

```json
{
  "mcpServers": {
    "ollama": {
      "command": "node",
      "args": ["/path/to/your/ollama-mcp-server/server.js"],
      "env": {
        "OLLAMA_API": "http://localhost:11434"
      }
    }
  }
}
```

---

## Project Structure

```
Ollama-MCP-Server/
â”œâ”€â”€ server.js              # Main MCP server implementation (ES modules)
â”œâ”€â”€ package.json            # Dependencies and project info (with "type": "module")
â”œâ”€â”€ Dockerfile              # Docker build instructions
â”œâ”€â”€ docker-compose.yml      # Docker Compose configuration
â”œâ”€â”€ .env.example           # Environment variables example
â”œâ”€â”€ LICENSE                 # GPL v2.0 license
â””â”€â”€ README.md              # This file
```

---

## Development

### Project Structure

```
Ollama-MCP-Server/
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ config/            # Configuration management
â”‚   â”‚   â””â”€â”€ index.js       # Environment and config validation
â”‚   â”œâ”€â”€ handlers/          # MCP tool handlers
â”‚   â”‚   â”œâ”€â”€ schemas.js     # Tool definitions and schemas
â”‚   â”‚   â””â”€â”€ tools.js       # Tool implementation handlers
â”‚   â”œâ”€â”€ utils/             # Utility modules
â”‚   â”‚   â”œâ”€â”€ http-client.js # HTTP client with retry logic
â”‚   â”‚   â”œâ”€â”€ logger.js      # Structured logging utility
â”‚   â”‚   â””â”€â”€ validation.js  # Input validation utilities
â”‚   â””â”€â”€ server.js          # Main server implementation
â”œâ”€â”€ tests/                 # Test files
â”‚   â”œâ”€â”€ config.test.js     # Configuration tests
â”‚   â”œâ”€â”€ schemas.test.js    # Schema tests
â”‚   â”œâ”€â”€ validation.test.js # Validation tests
â”‚   â””â”€â”€ setup.js           # Test setup and mocks
â”œâ”€â”€ .github/workflows/     # CI/CD workflows
â”‚   â””â”€â”€ ci.yml             # GitHub Actions workflow
â”œâ”€â”€ server.js              # Entry point (backwards compatible)
â”œâ”€â”€ package.json           # Dependencies and scripts
â”œâ”€â”€ jest.config.json       # Jest test configuration
â”œâ”€â”€ eslint.config.js       # ESLint configuration
â”œâ”€â”€ Dockerfile             # Docker build instructions
â”œâ”€â”€ docker-compose.yml     # Docker Compose configuration
â”œâ”€â”€ .env                   # Environment variables example
â”œâ”€â”€ .gitignore             # Git ignore patterns
â”œâ”€â”€ LICENSE                # GPL v2.0 license
â””â”€â”€ README.md              # This file
```

### Development Setup

1. **Clone the repository**:
   ```bash
   git clone https://github.com/mupoese/Ollama-MCP-Server.git
   cd Ollama-MCP-Server
   ```

2. **Install dependencies**:
   ```bash
   npm install
   ```

3. **Run linting**:
   ```bash
   npm run lint          # Check for issues
   npm run lint:fix      # Auto-fix issues
   ```

4. **Run tests**:
   ```bash
   npm test              # Run all tests
   npm run test:watch    # Run tests in watch mode
   npm run test:coverage # Run tests with coverage
   ```

5. **Run validation** (lint + test):
   ```bash
   npm run validate
   ```

### Code Quality

- **ESLint**: Enforces consistent code style and catches potential issues
- **Jest**: Comprehensive test suite with >80% coverage
- **Structured Logging**: Proper error handling and debugging capabilities
- **Input Validation**: Robust validation for all tool inputs
- **Retry Logic**: HTTP requests include exponential backoff retry logic
- **Modular Architecture**: Clean separation of concerns
- **AI Law Compliance**: Full LAW-001 implementation with learning cycles

### ðŸ” AI Core Architecture

The server implements a comprehensive AI governance and learning system:

#### Directory Structure
```
ai_core/
â”œâ”€â”€ law_enforcer.js      # LAW-001 compliance validation
â”œâ”€â”€ learning_cycle.js    # 6-step learning cycle implementation
â””â”€â”€ snapshot_mem.js      # Memory and snapshot management

logic/
â”œâ”€â”€ pattern_detector.js  # Pattern detection and deviation analysis
â””â”€â”€ proposed_logic_update.ai

governance/
â”œâ”€â”€ law_control.governance  # Governance framework
â””â”€â”€ governance.vote        # Voting system

memory/
â””â”€â”€ snapshots/            # Automatic snapshot storage

config/
â”œâ”€â”€ ai_status.json       # AI system status and dependencies
â””â”€â”€ memory_config.json   # Memory system configuration
```

#### Learning Cycle Process

Every tool execution triggers a 6-step learning cycle:

1. **Input Collection**: Structures input as JSON schema
2. **Action Determination**: Analyzes input and determines action per current logic
3. **Action Execution**: Executes action and registers direct reaction
4. **Reaction Registration**: Records system response and reaction data
5. **Output Evaluation**: Evaluates output vs expected outcomes, detects deviations
6. **Snapshot Generation**: Creates and stores snapshot with all cycle data

#### Memory & Pattern Detection

- **Automatic Loading**: Snapshots loaded on startup (`memory.load_snapshots=True`)
- **Pattern Analysis**: Detects recurring patterns and systematic deviations
- **Escalation System**: Automatically escalates patterns above threshold (default: 3)
- **Cleanup**: Removes unused/deviated files as specified in law.ai

#### Governance System

- **Law Control**: All core AI logic updates require explicit governance approval
- **Voting Mechanism**: Implements democratic voting for logic changes
- **Admin Override**: Emergency overrides logged and require retroactive approval
- **Audit Trail**: All governance actions automatically logged and snapshot-generated

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `OLLAMA_API` | `http://host.docker.internal:11434` | Ollama API endpoint |
| `SILENCE_STARTUP` | `false` | Suppress startup logs for MCP compatibility |
| `DEBUG` | `false` | Enable debug logging |
| `REQUEST_TIMEOUT` | `30000` | HTTP request timeout in milliseconds |
| `MAX_RETRIES` | `3` | Maximum number of retry attempts |
| `AI_CORE_ENABLED` | `true` | Enable AI core learning cycle system |
| `LEARNING_CYCLE_AUTO` | `true` | Automatically trigger learning cycles |
| `PATTERN_THRESHOLD` | `3` | Pattern detection threshold |
| `MEMORY_LOAD_SNAPSHOTS` | `true` | Load snapshots on startup |

### CI/CD

The project includes a GitHub Actions workflow that:
- Runs linting and tests on Node.js 18.x and 20.x
- Builds and tests Docker image
- Runs security audits
- Reports test coverage

---

## Troubleshooting

### Common Issues

**Q: MCP server times out during initialization**  
**A:** Ensure the server implements proper MCP protocol (JSON-RPC over stdin/stdout), not HTTP REST. Check that Ollama is running on the specified API endpoint.

**Q: "Unexpected token" JSON parsing error**  
**A:** The server is sending non-JSON output to stdout. All logging must go to stderr, not stdout. Set `SILENCE_STARTUP=true` to prevent this issue.

**Q: "ERR_REQUIRE_ESM" error**  
**A:** The MCP SDK requires ES modules. Make sure your package.json includes `"type": "module"` and uses `import` statements instead of `require()`.

**Q: Docker container can't connect to Ollama**  
**A:** Check your `OLLAMA_API` setting. Use `host.docker.internal` for Windows/Mac, or find your Docker bridge IP on Linux.

**Q: Claude Desktop doesn't show the MCP server**  
**A:** Verify your `claude_desktop_config.json` syntax and restart Claude Desktop. Check the MCP server logs for errors.

**Q: Server works locally but fails in Docker**  
**A:** Ensure you're using the correct Docker image (rebuilt after ES module changes) and proper environment variables.

### Debug Steps

1. **Test Ollama directly:**
   ```bash
   curl http://localhost:11434/api/tags
   ```

2. **Check Docker connectivity:**
   ```bash
   docker run --rm alpine ping host.docker.internal
   ```

3. **Test MCP server locally:**
   ```bash
   # Clone and test locally first
   git clone https://github.com/mupoese/Ollama-MCP-Server.git
   cd Ollama-MCP-Server
   npm install
   node server.js
   ```

4. **View MCP server logs:**
   Check Claude Desktop developer tools or console for MCP connection logs.

5. **Rebuild Docker image after changes:**
   ```bash
   docker build -t docker.io/mup1987/ollama-mcp-server:latest .
   ```

---

## Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## License

This project is licensed under the GNU General Public License v2.0.  
See `LICENSE` file for the complete license text.

---

## Support & Maintenance

- **Author/Maintainer:** Mupoese
- **Issues/Bugs:** via GitHub Issues
- **Feature Requests:** via Pull Request or GitHub Issue
- **Email:** info@mupoese.nl

---

## Buy Me a Coffee â˜•

Find this project useful? Want to support development?  
Don't forget to buy me a coffee!

[![Buy Me a Coffee](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-%23FFDD00.svg?style=flat-square&logo=buy-me-a-coffee&logoColor=black)](https://buymeacoffee.com/mup1987)

âž¡ï¸ **[https://buymeacoffee.com/mup1987](https://buymeacoffee.com/mup1987)**

---

## Additional Resources

- [Model Context Protocol Documentation](https://modelcontextprotocol.io/)
- [Ollama Documentation](https://ollama.ai/docs)
- [Claude Desktop MCP Setup Guide](https://claude.ai/docs/mcp)

---

> **Note:**  
> This README is a living document and will be expanded with each major update.
